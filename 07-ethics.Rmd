
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Ethics of AI

The use of artificial intelligence (AI) and in particular, generative AI, in coding has raised a number of ethical concerns. We will highlight several current concerns, however please be aware that this is a dynamic field and the possible implications of this technology is continuing to develop. It is critical that we as a society continue to evaluate and predict what the consequences of the use of AI will be, so that we can mitigate harmful effects.

## Major concerns

In this chapter we will discuss the following concerns:

1) Code that contributes to Bias - AI models are built on data and code that were created by biased humans, this bias can be further perpetuated
1) Code that contributes to misinformation - fake or manipulated data used to help design algorithms could be believed to be correct and this could be further propagated
1) Code that is unintelligible - Developers need to follow best practices with code generated by AI just like code generated by human developers, this includes figuring out how the code works, how it integrates with other code, as well as annotating and documenting how to use the code 
1) Code that has bugs - Code that may not be optimal for a given situation may be inadvertently used by those with less familiarity, which may result in faulty software
1) Code that has security issues - Code may not be optimized for security if not adequately evaluated
1) Code may violate privacy - Generative AI models have access to large amounts of data that is currently unregulated and may include data that should be protected for privacy reasons
1) Code may violate copyright - The code used for the generative AI model may used code that has copyright laws that require attribution or do not allow reuse and it may not be clear where the code came from
1) Code may be harmful - Currently it is not clear how well generative AI models restrict the creation of code that will be used for goals that harm others 



**It is essential to address these ethical concerns and ensure that the use of AI in coding is done in a responsible and transparent manner.** This could be done through ensuring the quality of the data used to train AI systems, promoting transparency in AI-generated code, and implementing safeguards against the creation of harmful or biased code. By doing so, we can harness the potential of AI to improve and transform the way we write and optimize code while maintaining ethical standards.

Another critical point is that those who use AI tools to write code or to understand code need to recognize their value in the process. While AI systems are useful, they do not replace the strengths that humans have for innovating new ways to write code, evaluating how the code integrates into the larger picture of a project, or in evaluating the downstream consequences of the code. Computer science is a field that has historically lacked diversity and new learners can often feel intimidated. There is the potential that new learners may feel even more discouraged as they learn to write code when witnessing AI tools write code. It is critical that we support diverse new learners of computer science, as we will continue to need human involvement in the development and use of AI tools.

## Bias

One of the biggest concerns is the potential for AI to create biased code. AI systems are trained on data created by humans. If this data used to train the system is biased, the resulting code could also be biased. This could lead to discrimination against certain groups of people, such as those with certain ethnic or cultural backgrounds, genders, ages, sexuality, capabilities, religions or other group affiliations. 

<!-- It is well known that data and code are often biased. Want to add examples!  -->


### Avoiding Bias

Here are some additional tips for using AI responsibly in coding to avoid bias:

* Be aware of the potential biases in the data that is used to train AI systems.

## Misinformation


### Reducing Misinformation

* Be aware that some AI tools currently make up false information based on artifacts of the algorithm. Do not assume that everything that the algorithm produces is real or correct. 

## Unitelligible Code

There is risk that those less aware of best coding practices use AI-generated code and do not follow these practices. This could make it difficult for others to understand how the code works and could make it hard to identify and fix any issues that may arise. This could result in negative consequences, such as system crashes or security breaches, that could have been avoided if the code had been written by an experienced and savvy human programmer.


### Avoiding unintelligible code

Tips to avoid creating unintelligible code include:

 * Code should be reviewed by experienced programmers.
 * Code should be annotated throughout to explain what the code is doing.
 * Documentation should be created that describes how to use the code properly.
 
 
## Faulty Code


### Reducing faulty code

* Do not assume that the code generate by AI is correct.
* Realize that AI is only as good or up-to-date as what it was trained on, the code may be generated using out-of-date code. Look up packages and functions used to ensure if the code is up-to-date.
* Make sure that you understand the code that you are using. AI can be used to help you understand what the code is doing, but consult with experts when needed.
* 



## Security issues


### Reducing security issues

Follow best practices for data/code security including:

* Check that all passwords, access tokens (like API keys), security certificates are not saved in a public place where anyone can access or tamper with them
* Check that no sensitive data, such as Personal Identifiable Information (PII) becomes public through the code
* Utilize encryption and other security practices where needed
* Consult with an expert about data security if you think your code could possibly cause someone to access protected data who is not authorized to access it
* 

## Privacy issues

### Reducing privacy issues

## Violating Copyright

When AI systems are trained on data, they may also learn and incorporate code from that data. This means that AI-generated code could potentially infringe on the copyright of the original author of the code. For example, if an AI system is trained on a GitHub repository that contains code written by a human programmer, the AI system could generate code that is identical to or similar to the code in the GitHub repository. If the AI system then uses this code without permission from the original author, this could constitute copyright infringement. In general, we want programmers to feel comfortable sharing their code openly without fear they won't be credited.
Similarly, AI systems could potentially infringe on intellectual property rights by using code that is protected by trademarks or patents. For example, if an AI system is trained on a training manual that contains code that is protected by a trademark, the AI system could generate code that is identical to or similar to the code in the training manual. If the AI system then uses this code without permission from the trademark owner, this could constitute trademark infringement.

### Avoiding copyright violations

* Obtain permission from the copyright holders of any code that you use to train the AI system. Only use code that is in the public domain or that has been licensed for use by the AI system's owner.
* Cite any GitHub repositories or training manuals you might use in your code

## Harmful code

Another major concern is the use of AI to generate malicious code. For instance, AI could be used to create code that spreads malware or hacks into computer systems. This could cause severe damage to individuals and organizations, including data breaches and financial losses.


### Avoiding harmful code

* Be careful about what code you share publicly, as it could be used for malicious purposes.








