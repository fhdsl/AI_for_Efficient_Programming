
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Ethics of AI

The use of artificial intelligence (AI) and in particular, generative AI, in coding has raised a number of ethical concerns. We will highlight several current concerns, however please be aware that this is a dynamic field and the possible implications of this technology is continuing to develop. It is critical that we as a society continue to evaluate and predict what the consequences of the use of AI will be, so that we can mitigate harmful effects.

## Major concerns

In this chapter we will discuss the following concerns:

1) Code that contributes to Bias - AI models are built on data and code that were created by biased humans, this bias can be further perpetuated
1) Code that contributes to misinformation - fake or manipulated data used to help design algorithms could be believed to be correct and this could be further propagated
1) Code that is unintelligible - Developers need to follow best practices with code generated by AI just like code generated by human developers, this includes figuring out how the code works, how it integrates with other code, as well as annotating and documenting how to use the code 
1) Code that has bugs - Code that may not be optimal for a given situation may be inadvertently used by those with less familiarity, which may result in faulty software
1) Code that has security issues - Code may not be optimized for security if not adequately evaluated
1) Code may violate privacy - Generative AI models have access to large amounts of data that is currently unregulated and may include data that should be protected for privacy reasons
1) Code may violate copyright - The code used for the generative AI model may used code that has copyright laws that require attribution or do not allow reuse and it may not be clear where the code came from
1) Code may be harmful - Currently it is not clear how well generative AI models restrict the creation of code that will be used for goals that harm others 



**It is essential to address these ethical concerns and ensure that the use of AI in coding is done in a responsible and transparent manner.** This could be done through ensuring the quality of the data used to train AI systems, promoting transparency in AI-generated code, and implementing safeguards against the creation of harmful or biased code. By doing so, we can harness the potential of AI to improve and transform the way we write and optimize code while maintaining ethical standards.


## Bias

One of the biggest concerns is the potential for AI to create biased code. AI systems are trained on data created by humans. If this data used to train the system is biased, the resulting code could also be biased. This could lead to discrimination against certain groups of people, such as those with certain ethnic or cultural backgrounds, genders, ages, sexuality, capabilities, religions or other group affiliations.

### Avoiding Bias

Here are some additional tips for using AI responsibly in coding to avoid bias:

* Be aware of the potential biases in the data that is used to train AI systems.

## Misinformation


### Reducing Misinformation

## Unitelligable Code

There is risk that those less aware of best coding practices use AI-generated code and do not follow these practices. This could make it difficult for others to understand how the code works and could make it hard to identify and fix any issues that may arise. This could result in negative consequences, such as system crashes or security breaches, that could have been avoided if the code had been written by an experienced and savvy human programmer.


### Avoiding unitelligable code


## Faulty Code


### Reducing faulty code

* Make sure that you understand the code that you are using, even if it was generated by AI.

## Secuirty issues


### Reducing secruity issues


## Privacy issues

### Reducing privacy issues

## Violating Copyright

When AI systems are trained on data, they may also learn and incorporate code from that data. This means that AI-generated code could potentially infringe on the copyright of the original author of the code. For example, if an AI system is trained on a GitHub repository that contains code written by a human programmer, the AI system could generate code that is identical to or similar to the code in the GitHub repository. If the AI system then uses this code without permission from the original author, this could constitute copyright infringement. In general, we want programmers to feel comfortable sharing their code openly without fear they won't be credited.
Similarly, AI systems could potentially infringe on intellectual property rights by using code that is protected by trademarks or patents. For example, if an AI system is trained on a training manual that contains code that is protected by a trademark, the AI system could generate code that is identical to or similar to the code in the training manual. If the AI system then uses this code without permission from the trademark owner, this could constitute trademark infringement.

### Avoiding copyright violations

* Obtain permission from the copyright holders of any code that you use to train the AI system. Only use code that is in the public domain or that has been licensed for use by the AI system's owner.
* Cite any GitHub repositories or training manuals you might use in your code

## Harmful code

Another major concern is the use of AI to generate malicious code. For instance, AI could be used to create code that spreads malware or hacks into computer systems. This could cause severe damage to individuals and organizations, including data breaches and financial losses.


### Avoiding harmful code

* Be careful about what code you share publicly, as it could be used for malicious purposes.








